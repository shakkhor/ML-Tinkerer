{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gensim modules\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# random\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, sources):\n",
    "        self.sources = sources\n",
    "        \n",
    "        flipped = {}\n",
    "        \n",
    "        # make sure that keys are unique\n",
    "        for key, value in sources.items():\n",
    "            if value not in flipped:\n",
    "                flipped[value] = [key]\n",
    "            else:\n",
    "                raise Exception('Non-unique prefix encountered')\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    yield LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no])\n",
    "    \n",
    "    def to_array(self):\n",
    "        self.sentences = []\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    self.sentences.append(LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no]))\n",
    "        return self.sentences\n",
    "    \n",
    "    def sentences_perm(self):\n",
    "        shuffled = list(self.sentences)\n",
    "        random.shuffle(shuffled)\n",
    "        return shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sources = {'test-neg.txt':'TEST_NEG', 'test-pos.txt':'TEST_POS', 'train-neg.txt':'TRAIN_NEG', 'train-pos.txt':'TRAIN_POS', 'train-unsup.txt':'TRAIN_UNS'}\n",
    "\n",
    "sentences = LabeledLineSentence(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\88015\\Anaconda3\\envs\\thesis\\lib\\site-packages\\ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(min_count=1, window=10, vector_size=100, sample=1e-4, negative=5, workers=7)\n",
    "\n",
    "model.build_vocab(sentences.to_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\88015\\Anaconda3\\envs\\thesis\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n"
     ]
    }
   ],
   "source": [
    "model.train(sentences, total_examples=model.corpus_count, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aragorn', 0.7731785774230957),\n",
       " ('syllabic', 0.7168655395507812),\n",
       " ('ohara', 0.7154890894889832),\n",
       " ('eowyn', 0.7096154093742371),\n",
       " ('middleton', 0.6969672441482544),\n",
       " ('commishioner', 0.6917276382446289),\n",
       " ('basso', 0.6900217533111572),\n",
       " ('untutored', 0.68355393409729),\n",
       " ('mamodo', 0.6806982159614563),\n",
       " ('boromir', 0.6781603097915649)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('gandalf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.13913268,  0.15021321, -0.03531564, -0.28943199, -0.03138167,\n",
       "       -0.22017106,  0.32938755,  0.15985407, -0.12201687,  0.06483268,\n",
       "        0.09612474,  0.03355727,  0.03962829,  0.2830447 , -0.17131598,\n",
       "       -0.00868482, -0.104504  , -0.1697655 , -0.03821738, -0.14742668,\n",
       "       -0.0926893 ,  0.15509811,  0.06425036,  0.0541451 , -0.14582181,\n",
       "       -0.22006164,  0.10749359, -0.07207451,  0.12976101,  0.21326768,\n",
       "       -0.06379854, -0.04967392, -0.11519434, -0.16500533,  0.03110348,\n",
       "        0.06954801,  0.24743034,  0.0374753 , -0.01505366,  0.18005267,\n",
       "       -0.05945515,  0.03950237,  0.06424104,  0.01931917, -0.03325284,\n",
       "        0.06662767,  0.07513139,  0.14157304,  0.24926299, -0.02202017,\n",
       "       -0.07397141,  0.12651265,  0.01655136, -0.05342555,  0.12718171,\n",
       "       -0.12258115, -0.1112871 ,  0.06722842, -0.07999547,  0.23850127,\n",
       "        0.07700711,  0.15600057,  0.07784322,  0.22602975,  0.10866074,\n",
       "       -0.18004186,  0.13781495, -0.05266292, -0.04609859,  0.15847464,\n",
       "        0.03714758,  0.13175964,  0.10867595,  0.00656177,  0.08719366,\n",
       "        0.17163821, -0.03702564,  0.09977927,  0.058628  , -0.07527161,\n",
       "        0.02720392,  0.07950003,  0.00516167,  0.10735475,  0.0306585 ,\n",
       "        0.1362481 ,  0.14873898, -0.23165445, -0.00449057,  0.05560182,\n",
       "       -0.00555827,  0.11170208, -0.06208971,  0.22523093, -0.15215988,\n",
       "       -0.21892472,  0.02616624, -0.06882461, -0.05891301,  0.05401289], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['TRAIN_NEG_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('./imdb.d2v')\n",
    "model = Doc2Vec.load('./imdb.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arrays = np.zeros((25000, 100))\n",
    "train_labels = np.zeros(25000)\n",
    "\n",
    "for i in range(12500):\n",
    "    prefix_train_pos = 'TRAIN_POS_' + str(i)\n",
    "    prefix_train_neg = 'TRAIN_NEG_' + str(i)\n",
    "    train_arrays[i] = model[prefix_train_pos]\n",
    "    train_arrays[12500 + i] = model[prefix_train_neg]\n",
    "    train_labels[i] = 1\n",
    "    train_labels[12500 + i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10814173  0.02058459  0.02001575 ...,  0.00272425  0.07071726\n",
      "  -0.23649846]\n",
      " [ 0.49629509 -0.17324495 -0.06872885 ...,  0.5641169   0.16677722\n",
      "  -0.36179718]\n",
      " [ 0.01649117 -0.29606307  0.02630273 ...,  0.1075986   0.23505121\n",
      "  -0.26756456]\n",
      " ..., \n",
      " [-0.22587335 -0.20128927 -0.08237034 ..., -0.19372711 -0.20316158\n",
      "  -0.37590554]\n",
      " [ 0.15669258 -0.28902137  0.52362788 ...,  0.01294029  0.03904394\n",
      "  -0.15000959]\n",
      " [ 0.15157355 -0.13107835 -0.04001979 ..., -0.03206924 -0.04616274\n",
      "  -0.13328114]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (train_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print (train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arrays = np.zeros((25000, 100))\n",
    "test_labels = np.zeros(25000)\n",
    "\n",
    "for i in range(12500):\n",
    "    prefix_test_pos = 'TEST_POS_' + str(i)\n",
    "    prefix_test_neg = 'TEST_NEG_' + str(i)\n",
    "    test_arrays[i] = model[prefix_test_pos]\n",
    "    test_arrays[12500 + i] = model[prefix_test_neg]\n",
    "    test_labels[i] = 1\n",
    "    test_labels[12500 + i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression_classifier = LogisticRegression()\n",
    "LogisticRegression_classifier.fit(train_arrays, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61992000000000003"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression_classifier.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTree_classifier = DecisionTreeClassifier(random_state=1)\n",
    "DecisionTree_classifier.fit(train_arrays, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54203999999999997"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTree_classifier.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_classifier = SVC()\n",
    "SVM_classifier.fit(train_arrays, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63100000000000001"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_classifier.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_Classifier = MLPClassifier()\n",
    "MLP_Classifier.fit(train_arrays, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65515999999999996"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_Classifier.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_Classifier = GaussianNB()\n",
    "GaussianNB_Classifier.fit(train_arrays, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5242"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_Classifier.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
